# sex
plot(adu$sex, adu$income)
sex = ifelse(adu$sex=="Male","남","여")
adu$sex = factor(sex, levels=c("여","남"))
# capitalgain
gain = ifelse(adu$`capital-gain`==0,"무","유") # capital이 있는경우/ 없는경우
adu$`capital-gain` = factor(gain, levels=c("무","유"))
# capitalloss
loss = ifelse(adu$`capital-loss`==0,"무","유")
adu$`capital-loss` = factor(loss, levels=c("무","유"))
# hours-per-week
summary(adu$`hours-per-week`)
hist(adu$`hours-per-week`)
table(adu$`hours-per-week`)
hours = c()
hours[adu$`hours-per-week`<=39]="40시간 미만"
hours[adu$`hours-per-week`>39 & adu$`hours-per-week`<45]="40시간 이상 45시간 미만"
hours[adu$`hours-per-week`>=45]="45시간 이상"
adu$`hours-per-week` = factor(hours, levels=c("40시간 미만","40시간 이상 45시간 미만","45시간 이상"))
### transaction 데이터 만들기
library(arules)
library(arulesViz)
str(adu)
adu = as(adu, 'transactions')
### 연관성분석
adu_rule1 = apriori(adu, parameter=list(support=0.01,confidence=0.2,minlen=3,maxlen=11))
summary(adu_rule1)
adu_rule2 = apriori(adu, parameter=list(support=0.05,confidence=0.2,minlen=3,maxlen=11))
summary(adu_rule2)
itemFrequencyPlot(adu, support=0.05)
### 연관규칙평가
rule_large = subset(adu_rule2, rhs %pin% c("income=large"))
large_bylift = inspect(sort(rule_large[1:20]),by="lift")
large_bysupport = inspect(sort(rule_large[1:20]),by="support") ## age=중노년층, hours 45시간 이상 정도가 많이 나옴을 확인
rule_large2 = subset(rule_large, lhs %ain% c("age=중노년층","hours-per-week=45시간 이상"))
large2_bylift = inspect(sort(rule_large2),by="lift") ## race=백인, capital-loss=무, sex=남 이 많이 나옴을 확인
# income-large <= age=중노년층, hours=45시간 이상, sex=남, race=백인, capital-loss=무, relationship=배우자O
rule_small = subset(adu_rule2, rhs %pin% c("income=small"))
small_bylift = inspect(sort(rule_small[1:20]),by="lift")
small_bysupport = inspect(sort(rule_small[1:20]),by="support") ## hours 40시간 미만 정도가 많이 나옴을 확인
rule_small2 = subset(rule_small, lhs %in% c("hours-per-week=40시간 미만"))
rule_small3 = subset(rule_small2, lhs %ain% c("age=청장년층","sex=여")) ## age=청장년층, sex=여 가 많이 나옴을 확인
small2_bylift = inspect(sort(rule_small3),by="lift")
# income-small <= age=청장년층, hours=40시간 미만, sex=여, capital=gain=무, realtionship=배우자X
### 시각화
library(arulesViz)
plot(rule_large2)
plot(sort(rule_large2, by="support"),method="grouped")
plot(rule_small3)
plot(sort(rule_small3, by="support"),method="grouped")
plot(rule_large2,method="paracoord")
plot(rule_small3,method="paracoord")
rm(list=ls())
train_x = read.csv("train_X.csv")
setwd("C:/Users/USER/Desktop/투빅스/2주차 나이브베이즈/test_X")
train_x = read.csv("train_X.csv")
train_y = read.csv("train_y.csv")
test_x = read.csv("test_X.csv")
test_y = read.csv("test_y.csv")
train_y <- train_y[,2]
convert_x = function(x){ # yes / no => 1 / 0 해주는 함수
x = x[,-1] # 필요없는 행 제거
x = ifelse(x=="Yes",1,0)
return(x)
}
model = function(train_x,train_y){
x = convert_x(train_x)
ham = apply(x[which(train_y=="ham"),],2,sum) + 1 # smoothing
spam = apply(x[which(train_y=="spam"),],2,sum) + 1
# 확률값이 너무 작아 log를 취해줌
target_h = log(length(train_y[which(train_y=="ham")])/length(train_y)) # 조건부확률
target_s = log(length(train_y[which(train_y=="spam")])/length(train_y))
prob_h = log(ham/sum(ham)) # 사전확률
prob_s = log(spam/sum(spam))
return(list(target_h,target_s,prob_h,prob_s))
}
ham
model = function(train_x,train_y){
x = convert_x(train_x)
ham = apply(x[which(train_y=="ham"),],2,sum) + 1 # smoothing
spam = apply(x[which(train_y=="spam"),],2,sum) + 1
# 확률값이 너무 작아 log를 취해줌
target_h = log(length(train_y[which(train_y=="ham")])/length(train_y)) # 조건부확률
target_s = log(length(train_y[which(train_y=="spam")])/length(train_y))
prob_h = log(ham/sum(ham)) # 사전확률
prob_s = log(spam/sum(spam))
return(list(target_h,target_s,prob_h,prob_s))
}
x = convert_x(train_x)
ham = apply(x[which(train_y=="ham"),],2,sum) + 1 # smoothing
ham
spam = apply(x[which(train_y=="spam"),],2,sum) + 1
target_h = log(length(train_y[which(train_y=="ham")])/length(train_y)) # 조건부확률
target_h
target_s
prob_h
target_s = log(length(train_y[which(train_y=="spam")])/length(train_y))
target_s
prob_h = log(ham/sum(ham)) # 사전확률
prob_h
setwd("C:/Users/USER/Desktop/투빅스/2주차 과제")
board <- read.csv("board.csv",F)
board <- as.matrix(board)
move_x = c(2,-2,2,-2,1,-1,1,-1)
move_y = c(1,1,-1,-1,2,2,-2,-2)
in_chess = function(a,b){
if(a>=0&&a<100&&b>=0&&b<100){return ("true")}
else{return ("false")}
}
min_knight = function(sx,sy,ex,ey){
count = 0
start = c(sx,sy)
queue = list(start)
while(length(queue)!=0){
xp = queue[[1]][1]
yp = queue[[1]][2]
xp = as.numeric(xp)
yp = as.numeric(yp)
queue = queue[-1]
if(xp == ex && yp == ey){
return(count)
break;
}
for(i in 0:8){
if(in_chess(xp+move_x[i],yp+move_y[i])=="false"){
return("error")
}
if(board[xp+move_x[i]][yp+move_y[i]]){
return("error")
}
board[xp+move_x[i]][yp+move_y[i]] = board[xp][yp] +1
queue = c(queue,list(xp+dx[i],yp+dy[i]))
count = count+1
}
}
}
min_knight(24,55,1,1)
setwd("C:/Users/USER/Desktop/투빅스/2주차 과제")
board <- read.csv("board.csv",F)
board <- as.matrix(board)
move_x = c(2,-2,2,-2,1,-1,1,-1)
move_y = c(1,1,-1,-1,2,2,-2,-2)
in_chess = function(a,b){
if(a>=0 & a<100 & b>=0 & b<100){return ("true")}
else{return ("false")}
}
min_knight = function(sx,sy,ex,ey){
count = 0
start = c(sx,sy)
queue = list(start)
while(length(queue)!=0){
xp = queue[[1]][1]
yp = queue[[1]][2]
xp = as.numeric(xp)
yp = as.numeric(yp)
queue = queue[-1]
if(xp == ex && yp == ey){
return(count)
break;
}
for(i in 0:8){
if(in_chess(xp+move_x[i],yp+move_y[i])=="false"){
return("error")
}
if(board[xp+move_x[i]][yp+move_y[i]]){
return("error")
}
board[xp+move_x[i]][yp+move_y[i]] = board[xp][yp] +1
queue = c(queue,list(xp+dx[i],yp+dy[i]))
count = count+1
}
}
}
min_knight(24,55,1,1)
setwd("C:/Users/USER/Desktop/투빅스/2주차 과제")
board <- read.csv("board.csv",F)
board <- as.matrix(board)
move_x = c(2,-2,2,-2,1,-1,1,-1)
move_y = c(1,1,-1,-1,2,2,-2,-2)
in_chess = function(a,b){
if(a>=0 && a<100 && b>=0 && b<100){return ("true")}
else{return ("false")}
}
min_knight = function(sx,sy,ex,ey){
count = 0
start = c(sx,sy)
queue = list(start)
while(length(queue)!=0){
xp = queue[[1]][1]
yp = queue[[1]][2]
xp = as.numeric(xp)
yp = as.numeric(yp)
queue = queue[-1]
if(xp == ex && yp == ey){
return(count)
break;
}
for(i in 0:8){
if(in_chess(xp+move_x[i],yp+move_y[i])=="false"){
return("error")
}
if(board[xp+move_x[i]][yp+move_y[i]]){
return("error")
}
board[xp+move_x[i]][yp+move_y[i]] = board[xp][yp] +1
queue = c(queue,list(xp+dx[i],yp+dy[i]))
count = count+1
}
}
}
min_knight(24,55,1,1)
vif(reg.ridge)
rm(list=ls())
library(arules)
data("AdultUCI")
adu <- AdultUCI
adu = na.omit(adu) # 결측치 제거
### 데이터 파악하기
str(adu) # 15개의 변수 중 반 이상이 factor 형임 => glm 이용
# age : int => factor => 0/1
age = ifelse(adu$age<=39,1,0) # 청장년층 / 중노년층
adu$age = factor(age,order=T)
# workclass : self-emp-inc 제외하고 거의 비슷한 income값을 가짐 => 그냥 제거
plot(workclass,income)
names(adu)
adu = adu[,-2]
# fnlwgt : 의미를 모르겠는 변수 => 제거
adu = adu[,-2]
# education : education-num 과 같은 의미의 변수 => 제거
adu = adu[,-2]
# education-num : factor => 0/1
edunum = ifelse(adu$`education-num`<=9,0,1) # 고졸 / 고졸이상
adu$`education-num` = factor(edunum, order=T)
# marital-status : factor => 0/1
plot(adu$marital,adu$income) # married-civ-spouse 과 아닌것의 차이가 큼
marital = ifelse(adu$`marital-status`=="Married-civ-spouse",1,0) # "Married-civ-spouse O" / "Married-civ-spouse X"
adu$`marital-status` = factor(marital, order=T)
table(adu$`marital-status`)
# occupation : factor => 0/1
# 소득을 기준으로 임의로 나눔
occupation = character(0)
occupation[adu$occupation %in% c("Exec-managerial","Craft-repair","Prof-speciality","Sales","Tech-support","Protective-serv")]=1
occupation[is.na(occupation)]=0
adu$occupation = factor(occupation, order=T)
# relationship : factor => 0/1
relationship = character(0)
relationship[adu$relationship %in% c("Husband","Wife")]=1 # 배우자인경우 / 아닌경우
relationship[is.na(relationship)]=0
adu$relationship = factor(relationship,order=T)
table(adu$relationship)
# race : factor
race = ifelse(adu$race=="White",1,0) # 백인인경우 / 아닌경우
adu$race = factor(race, order=T)
# sex
plot(adu$sex, adu$income)
sex = ifelse(adu$sex=="Male",1,0) # 남 / 여
adu$sex = factor(sex, order=T)
# capitalgain
gain = ifelse(adu$`capital-gain`==0,0,1) # capital이 있는경우/ 없는경우
adu$`capital-gain` = factor(gain, order=T)
# capitalloss
loss = ifelse(adu$`capital-loss`==0,0,1)
adu$`capital-loss` = factor(loss, order=T)
# hours-per-week
summary(adu$`hours-per-week`)
hist(adu$`hours-per-week`)
hours = c()
hours[adu$`hours-per-week`<=39]="40시간 미만"
hours[adu$`hours-per-week`>39 & adu$`hours-per-week`<45]="40시간 이상 45시간 미만"
hours[adu$`hours-per-week`>=45]="45시간 이상"
adu$`hours-per-week` = factor(hours, levels=c("40시간 미만","40시간 이상 45시간 미만","45시간 이상"))
table(adu$`hours-per-week`)
# income
income = ifelse(adu$income=="small",0,1)
adu$income = factor(income, order=T)
# native-country : 레벨이 너무 많음 => 제거
adu = adu[,-11]
str(adu)
### logistic regression
fit1 = glm(income~.,data=adu, family=binomial(link='logit'))
summary(fit1)
library(car)
vif(fit1) # marital-num , relationship 의 vif > 5이므로 제거
adu1 = adu[,c(-3,-5)]
fit2 = glm(income~.,data=adu1, family=binomial(link='logit'))
summary(fit2)
vif(fit2) # vif > 5 인 변수들을 제거함으로서 다중공선성 해결
### 변수선택
fit_low = glm(income~occupation,data=adu1, family=binomial(link='logit'))
forward = step(fit_low, scope=list(lower=fit_low,upper=fit2), direction="forward")
summary(forward) # income ~ occupation + `hours-per-week` + `capital-gain` + `education-num` + age + sex + `capital-loss` + race
backward = step(fit2, scope=list(lower=fit_low,upper=fit2), direction="backward")
summary(backward) # income ~ age + `education-num` + occupation + race + sex + `capital-gain` + `capital-loss` + `hours-per-week`
stepwise = step(fit_low, scope=list(lower=fit_low,upper=fit2), direction="both")
summary(stepwise) # income ~ age + `education-num` + occupation + race + sex + `capital-gain` + `capital-loss` + `hours-per-week`
# validation/prediction
set.seed(0127)
index <- sample(1:length(adu1[,1]),length(adu1[,1])*0.7,F)
train <- adu1[index,]
test <- adu1[-index,]
names(train)
fit.full = glm(income~.,data=train,family=binomial(link="logit"))
fit.con = glm(income~1,data=train,family=binomial(link="logit"))
fit.step = step(fit.con, scope=list(lower=fit.con,upper=fit.full),direction="both")
# income ~ age + `education-num` + occupation + race + sex + `capital-gain` + `capital-loss` + `hours-per-week`
glm.pred = predict(fit.step, newdata = test, type = "response")
pred = round(glm.pred)
table(pred,test$income) # 틀린것이 넘나 많음
### 다중공선성을 능형회귀로 해결해보자
# level이 3인 변수에 대해 가변수처리 : base 는 40시간 이상 45시간 미만 => 00
summary(adu)
under_40 = rep(0,nrow(adu))
for(i in 1:nrow(adu)){
under_40[i] = ifelse(adu[i,10]=="40시간 미만",1,0)
}
above_45 = rep(0,nrow(adu))
for(i in 1:nrow(adu)){
above_45[i] = ifelse(adu[i,10]=="45시간 이상",1,0)
}
adu$under_40 = factor(under_40,order=T)
adu$above_45 = factor(above_45,order=T)
adu = adu[,-10]
# validation/prediction
str(adu)
set.seed(0127)
index <- sample(1:length(adu[,1]),length(adu[,1])*0.7,F)
train <- adu[index,]
test <- adu[-index,]
fit = glm(income~.,data=train,family=binomial(link="logit"))
vif(fit) # marital 과 relationship 의 vif 가 30이상
library(glmnet)
reg.ridge = cv.glmnet(x=data.matrix(train[,-10]),y=data.matrix(train[,10]),family="binomial",alpha=0,nfold=10)
vif(reg.ridge)
coef(reg.ridge)
par(mfrow=c(1,1))
plot(reg.ridge)
reg.ridge$lambda.min
pred = predict(reg.ridge, data.matrix(test[,-10]),s = reg.ridge$lambda.min, type="class")
table(Actual = test[,10], Predicted = pred)
library(caret)
confusionMatrix(pred,test[,10]) # accuracy : 0.8196
reg.lasso = cv.glmnet(x=data.matrix(train[,-10]),y=data.matrix(train[,10]),family="binomial",alpha=1,nfold=10)
coef(reg.lasso)
plot(reg.lasso)
reg.lasso$lambda.min
pred = predict(reg.lasso, data.matrix(test[,-10]),s = reg.lasso$lambda.min, type="class")
table(Actual = test[,10], Predicted = pred)
confusionMatrix(pred,test[,10]) # accuracy : 0.8243
vif(reg.ridge)
coef(reg.ridge)
vif(fit) # marital 과 relationship 의 vif 가 30이상
rm(list=ls())
install.packages("caret")
install.packages("car")
install.packages("glmnet")
install.packages("nnet")
library(car)
library(glmnet)
library(caret)
##example##
getwd()
setwd("C:/Users/USER/Desktop/투빅스/2주차 glm")
full<-read.csv("project_data.csv", header=T, stringsAsFactor=F)
str(full)
#####
# 종속 설명
# 연속 연속 > 상관분석
# 범주 연속 > T검정
# 범주 범주 > 카이제곱
#####
# 0/1로 된 종속변수를 만들어보자!!
# 여기서 numeric과 factor는 동일한 효과
full$등급[full$등급!="청소년관람불가"] <-"청소년관람가" # 청소년 관람 or not
full$등급[full$등급=="청소년관람불가"]<-1
full$등급[full$등급=="청소년관람가"]<-0
full$등급 <- factor(full$등급,order=T)
full$구분[full$구분=="국내영화"]<-1
full$구분[full$구분=="국외영화"]<-0
full$구분<-as.numeric(full$구분)
str(full)
#일반적으로 범주형변수들간에는 상관계수대신 독립성검정을 할 수있다
#분석이랑은 상관없지만그냥 예시
m <- with(full,table(등급,구분))
par(mfrow=c(1,1))
barplot(m,beside=T, ylab="수",names.arg=c("국외영화","국내영화")) # 국내영화의 차이가 큼
addmargins(m)
chisq.test(m) #독립성검정
# pvalue가 작으면 귀무가설을 지지하는 정도가 낮음
#귀무가설 기각. 독립
###logistic regression###
#glm 코드설명
#glm(종속~독립.,데이터,family = binomial,possion,gamma 등등이 있음..)
?glm
#회귀분석하고 기본적인 포뮬라는 같다. 그냥 뒤에 family =binomial만 붙여주면 돰
names(full)
fit1<-glm(등급~구분,data=full,family=binomial(link = 'logit'))
summary(fit1)
# 베타계수 > 0 이면 영향력이 있다 정도로 생각
fit2<-glm(등급~구분+주제+선정성+폭력성+공포+약물+대사.지속성등.+모방위협,data=full,family=binomial(link = 'logit'))
summary(fit2)
vif(fit2)
#roc curve 그려보기
#roc 커브를 이용해서 이 모델이 얼마나 적합한지 알아보자
install.packages("pROC")
library(pROC)
par(mfrow=c(1,2))
y<-roc(등급~구분+주제+선정성+폭력성+공포+약물+대사.지속성등.,data=full,plot=T)
###변수선택
# 이 역시 회귀분석과 동일합니다!
forward<-step(fit1,scope=list(lower=fit1,upper=fit2),direction="forward") # AIC : 모델의 타당성을 평가, but error를 기준으로 하는 방법은 아님
summary(forward)
backward<-step(fit2,scope=list(lower=fit1,upper=fit2),direction="backward")
summary(backward)
stepwise<-step(fit1,scope=list(lower=fit1,upper=fit2),direction="both")
summary(stepwise)
#vaildation/prediction 해보기
set.seed(1)
index <- sample(1:length(full[,1]),length(full[,1])*0.7,F) # F : 복원추출x
# train : test 는 7:3 이므로 *0.7 만큼 데이터 샘플을 뽑음
#train/test 쪼개보기
train <- full[index,] # 전체의 0.7
test <- full[-index,] # 1-0.7 = 전체의 0.3
names(train)
fit.full <- glm(등급~구분+주제+선정성+폭력성+공포+약물+대사.지속성등.+모방위협,data=train,family=binomial(link = "logit"))
fit.con<-glm(등급~1,data=train,family=binomial(link = "logit"))
fit.step <- step(fit.con,scope=list(lower=fit.con,upper=fit.full),direction="both")
glm.pred <- predict(fit.step,newdata = test,type = "response") # 예측치
pred <- round(glm.pred)
table(pred,test$등급) # 여기서 틀린건 36개
36/length(test$등급) # 오류일 확률 계산
sum(diag(table(pred,test$등급)))/length(pred)
#multinomial인 경우
library(nnet)
data(iris)
str(iris)
set.seed(0127)
index <- sample(1:length(iris[,1]),length(iris[,1])*0.7,F)
train <- iris[index,]
test <- iris[-index,]
#multinom 이라는 함수 이용해주면 됨.
model <- multinom(Species~.,data=train, link = "logit")
summary(model)
p <- predict(model,newdata = test,type = "class")
table(p,test$Species)
#다중공선성 문제가 잇는 데이터를 능형회귀를 통해 해결해보자
setwd("C:/Users/USER/Desktop/투빅스/2주차 glm")
digit <- read.csv("digit.csv")
digit$label <- as.factor(digit$label)
set.seed(0127)
#데이터 갯수가 많으니까 트레인셋을 10프로만 뽑아볼게요
index <- sample(1:length(digit[,1]),length(digit[,1])*0.1,F)
train <- digit[index,]
test <- digit[-index,]
fit <- glm(label~.,data = train,family = binomial(link = "logit"))
#적합된 확률값들이 0또는 1이다 => perfect multicollinearty 의미
vif(fit)
#Error in vif.default(fit) : there are aliased coefficients in the model
#라고다들 뜨실텐데 완전 공선성이 있어서 추정이 불가능한 상태를 의미한다.
#이정도로 완전공선성인 데이터일때는 vif값을 제대로 볼 수도 없어서 변수선택도
#하지 못하는 상태가 된다
#능형회귀 사용 >>>> 가변수 처리를 해주어야함 !!!!!!!!
#glmnet 코드
#glmnet(x=설명변수,y=종속변수
#       family = 사용하고자 하는 종속변수 level 수에 따라 "binomial" "multinomial"
#       alpha = 0인경우 ridge/1인경우 lasso 0과1사이인 경우 elastic net
#       nfold = cross-validation 할 폴드의 수)
#능형회귀 이용한 모델적합
reg.ridge <- cv.glmnet(x= data.matrix(train[,-1]),y= data.matrix(train[,1]),
family = "binomial", alpha = 0,nfold=10)
coef(reg.ridge)
################################################################ 해당 람다에 대해 모델을 한번 더 적합 한 후 에러를 구해야함
plot(reg.ridge) # error율을 보여주는 것 (베타계수 축소하는것과 다른것)
reg.ridge$lambda.min # cv error 최소화하는 lambda값
pred <- predict(reg.ridge,data.matrix(test[,-1]),s= reg.ridge$lambda.min,type="class")
table(Actual= test[,1],Predicted = pred)
confusionMatrix(pred,test[,1]) #table 보다 test 셋에 대한 더많은 정보를 얻을 수 있음
# 라소
reg.lasso <- cv.glmnet(x= data.matrix(train[,-1]),y= data.matrix(train[,1]),
family = "binomial", alpha = 1, nfold=10)
# alpha = 0 릿지 / alpha = 1 라소
# alpha 0~1 이면 릿지라소 섞은 모델
coef(reg.lasso)
plot(reg.lasso)
# binomialDeri은 error와 비슷
reg.lasso$lambda.min
#cv error 최소화하는 lambda값
reg.lasso$lambda.1se
# 를 주로 사용한다 -> 과적합의 영향을 줄이는 람다!!!
# 에러는 람다민 보다는 크지만 과적합의 영향을 덜 받는
pred_2 <- predict(reg.lasso,data.matrix(test[,-1]), s= reg.lasso$lambda.min,
type="class")
table(Actual= test[,1],Predicted = pred_2)
confusionMatrix(pred,test[,1])
install.packages("caret")
install.packages("glmnet")
install.packages("car")
install.packages("nnet")
install.packages("pROC")
install.packages("car")
install.packages("glmnet")
install.packages("pROC")
install.packages("nnet")
install.packages("pROC")
coef(reg.lasso)
plot(reg.lasso)
reg.lasso$lambda.min
reg.lasso$lambda.1se
reg.lasso <- cv.glmnet(x= data.matrix(train[,-1]),y= data.matrix(train[,1]),
family = "binomial", alpha = 1, nfold=10)
reg.lasso
vif(fit)
pred.lse = predict(reg.lasso, data.matrix(test[,-10]),s = reg.lasso$lambda.lse, type="class")
